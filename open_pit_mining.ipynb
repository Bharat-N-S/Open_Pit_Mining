{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the following GPU(s):\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPU ID: 0, Name: NVIDIA GeForce RTX 3050 Laptop GPU, Load: 0.0%, Memory Free: 3964.0MB, Memory Used: 0.0MB, Memory Total: 4096.0MB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import GPUtil\n",
    "\n",
    "# Check if TensorFlow sees the GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"TensorFlow is using the following GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU detected by TensorFlow.\")\n",
    "\n",
    "# Use GPUtil to get detailed GPU information\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU ID: {gpu.id}, Name: {gpu.name}, Load: {gpu.load*100}%, Memory Free: {gpu.memoryFree}MB, Memory Used: {gpu.memoryUsed}MB, Memory Total: {gpu.memoryTotal}MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OES project open pit mining project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccessary Library\n",
    "import pandas as pd     \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the telemetry data (training)\n",
    "telemetry_train = pd.read_csv(r'D:\\DataScience\\openpitmining\\telemetry_for_operations_training.csv')\n",
    "\n",
    "# Load the operational labels (training)\n",
    "operations_labels_train = pd.read_csv('D:\\\\DataScience\\\\openpitmining\\\\operations_labels_training.csv')\n",
    "\n",
    "# Load the telemetry data (validation/test set)\n",
    "telemetry_validation = pd.read_csv('D:\\\\DataScience\\\\openpitmining\\\\telemetry_for_operations_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#checking the null values\n",
    "print(telemetry_train['create_dt'].isnull().sum())\n",
    "print(operations_labels_train['start_time'].isnull().sum())\n",
    "# Impute missing dates with a default value (use with caution)\n",
    "telemetry_train['create_dt'].fillna(pd.Timestamp('2023-01-01'), inplace=True)\n",
    "operations_labels_train['start_time'].fillna(pd.Timestamp('2023-01-01'), inplace=True)\n",
    "print(telemetry_train['create_dt'].isnull().sum())\n",
    "print(operations_labels_train['start_time'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge telemetry data with operational state labels on time and truck name\n",
    "# We'll use a time-based merge\n",
    "telemetry_train['create_dt'] = pd.to_datetime(telemetry_train['create_dt'], errors='coerce')\n",
    "operations_labels_train['start_time'] = pd.to_datetime(operations_labels_train['start_time'], errors='coerce')\n",
    "\n",
    "\n",
    "merged_data = pd.merge_asof(\n",
    "    telemetry_train.sort_values('create_dt'),\n",
    "    operations_labels_train.sort_values('start_time'),\n",
    "    left_on='create_dt',\n",
    "    right_on='start_time',\n",
    "    by='mdm_object_name',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Drop any rows where the merge didn’t work\n",
    "merged_data = merged_data.dropna(subset=['operation_kind_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming merged_data is your DataFrame and it already contains 'lat' and 'lon' columns\n",
    "\n",
    "# Calculate new features (e.g., speed change)\n",
    "merged_data['speed_change'] = merged_data['speed_gps'].diff().fillna(0)\n",
    "\n",
    "# Haversine function to calculate distance between two lat/lon points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    return 6371 * 2 * np.arcsin(np.sqrt(a))  # Earth radius = 6371 km\n",
    "\n",
    "# Create a new feature: distance traveled between consecutive GPS points\n",
    "merged_data['distance_traveled'] = pd.Series(haversine(\n",
    "    merged_data['lat'], merged_data['lon'],\n",
    "    merged_data['lat'].shift(1), merged_data['lon'].shift(1)\n",
    ")).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features (X) and the target (y)\n",
    "X = merged_data[['speed_gps', 'accel_forward_nn', 'accel_braking_nn', 'accel_angular_nn', 'accel_vertical_nn', 'speed_change', 'distance_traveled']]\n",
    "y = merged_data['operation_kind_id']\n",
    "\n",
    "# Split into training and test sets for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 5.]\n",
      "[0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Print unique classes before filtering\n",
    "print(np.unique(y_train))\n",
    "\n",
    "# Filter out the invalid class\n",
    "valid_classes = [0, 1, 2, 3]\n",
    "mask = y_train.isin(valid_classes)\n",
    "y_train_filtered = y_train[mask]\n",
    "X_train_scaled_filtered = X_train_scaled[mask]\n",
    "\n",
    "# Check unique classes again\n",
    "print(np.unique(y_train_filtered))  # Should output [0, 1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_filtered = y_train_filtered.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_class=5, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=5, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_scaled_filtered, y_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.4338022026306958\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the weighted F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Weighted F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features for validation data\n",
    "telemetry_validation['speed_change'] = telemetry_validation['speed_gps'].diff().fillna(0)\n",
    "\n",
    "# Create a new feature: distance traveled between consecutive GPS points\n",
    "telemetry_validation['distance_traveled'] = pd.Series(haversine(\n",
    "    telemetry_validation['lat'], telemetry_validation['lon'],\n",
    "    telemetry_validation['lat'].shift(1), telemetry_validation['lon'].shift(1)\n",
    ")).fillna(0)\n",
    "\n",
    "# Select the features\n",
    "X_validation = telemetry_validation[['speed_gps', 'accel_forward_nn', 'accel_braking_nn', 'accel_angular_nn', 'accel_vertical_nn', 'speed_change', 'distance_traveled']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have scaled your validation features using the same scaler\n",
    "from sklearn.preprocessing import StandardScalerd\n",
    "\n",
    "# Assuming you have a scaler already fitted on training data\n",
    "# If not, fit it on the training data first\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform on training data\n",
    "\n",
    "# Transform the validation data using the same scaler\n",
    "X_validation_scaled = scaler.transform(X_validation)  # Transform only\n",
    "\n",
    "# Make predictions on the scaled validation data\n",
    "y_validation_pred = xgb_model.predict(X_validation_scaled)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = telemetry_validation[['create_dt', 'mdm_object_name']].copy()  # Use copy to avoid SettingWithCopyWarning\n",
    "submission['operation_kind_id'] = y_validation_pred\n",
    "\n",
    "# Ensure the shape is correct\n",
    "expected_shape = (260111, 3)  # Replace with the actual number of rows if different\n",
    "assert submission.shape == expected_shape, f\"Expected shape {expected_shape}, but got {submission.shape}\"\n",
    "\n",
    "# Save the submission file as CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as 'submission.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
